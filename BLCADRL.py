# -*- coding: utf-8 -*-
"""rls.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ka7PeJ0jo_hNUi14X4Cc56H-vsBp59fb
"""

!pip install tensorflow==2.9.0 keras==2.9.0 gym keras-rl2

!pip install gym
!pip install tensorflow
!pip install keras
!pip install keras-rl2

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from rl.agents.dqn import DQNAgent
from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy, GreedyQPolicy, MaxBoltzmannQPolicy, LinearAnnealedPolicy
from rl.memory import SequentialMemory
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten
from tensorflow.keras.optimizers import Adam
import gym
import tensorflow as tf

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from rl.agents.dqn import DQNAgent
from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy, GreedyQPolicy, MaxBoltzmannQPolicy, LinearAnnealedPolicy
from rl.memory import SequentialMemory
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten
from tensorflow.keras.optimizers import Adam
import gym
import tensorflow as tf


np.random.seed(42)
tf.random.set_seed(42)


def train_and_evaluate(model, policy, env, nb_steps=15000):
    memory = SequentialMemory(limit=50000, window_length=1)
    dqn = DQNAgent(model=model, nb_actions=env.action_space.n, memory=memory, nb_steps_warmup=10, target_model_update=1e-2, policy=policy)
    dqn.compile(Adam(learning_rate=1e-5), metrics=['mae'])

   
    history = dqn.fit(env, nb_steps=nb_steps, visualize=False, verbose=2)

  
    test_history = dqn.test(env, nb_episodes=10, visualize=False)

    return history, test_history


def plot_and_table_reward_histories(histories, policy_names, filename):
    plt.figure(figsize=(18, 6))

    average_rewards = []
    top3_rewards = []

    for history, policy_name in zip(histories, policy_names):
        rewards = history.history['episode_reward']
        plt.plot(rewards, label=policy_name)
        average_rewards.append(np.mean(rewards))
        top3_rewards.append(sorted(rewards, reverse=True)[:3])

        
        max_reward_index = np.argmax(rewards)
        max_reward = rewards[max_reward_index]
        plt.scatter(max_reward_index, max_reward, s=100, facecolors='none', edgecolors='r', linewidths=2)
        plt.annotate('Max Reward\n({:.2f})'.format(max_reward),
                     xy=(max_reward_index, max_reward),
                     xytext=(max_reward_index + 2, max_reward + 10),
                     arrowprops=dict(facecolor='black', arrowstyle="->"))

    plt.xlabel('Steps')
    plt.ylabel('Episode Reward')
    plt.title('Training Episode Reward Comparison', fontsize=18, fontweight='bold', pad=20)
    plt.legend(loc='upper left', fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)

    plt.tight_layout()
    plt.savefig(filename, dpi=300)
    plt.show()

    reward_data = {
        'Policy': policy_names,
        'Average Reward': average_rewards,
        'Top 3 Rewards': top3_rewards
    }

    reward_df = pd.DataFrame(reward_data)
    reward_df.to_csv('reward_comparison_table.csv', index=False)
    print(reward_df)


def create_model(env):
    model = Sequential()
    model.add(Flatten(input_shape=(1,) + env.observation_space.shape))
    model.add(Dense(48))
    model.add(Activation('relu'))
    model.add(Dense(48))
    model.add(Activation('relu'))
    model.add(Dense(env.action_space.n))
    model.add(Activation('linear'))
    return model


def compare_models(env, nb_steps=15000):
    policies = [
        EpsGreedyQPolicy(),
        BoltzmannQPolicy(),
        GreedyQPolicy(),
        MaxBoltzmannQPolicy(),
        LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05, nb_steps=10000)
    ]
    policy_names = [
        'EpsGreedyQPolicy',
        'BoltzmannQPolicy',
        'GreedyQPolicy',
        'MaxBoltzmannQPolicy',
        'LinearAnnealedPolicy'
    ]

    histories = []
    for policy, policy_name in zip(policies, policy_names):
        print(f"\nTraining with policy: {policy_name}")
        model = create_model(env)
        history, test_history = train_and_evaluate(model, policy, env, nb_steps)
        histories.append(history)

    
        print("Test Results:")
        for i, episode in enumerate(test_history.history['episode_reward']):
            print(f"Episode {i+1}: reward: {episode}")

  
    plot_and_table_reward_histories(histories, policy_names, 'training_rewards_comparison.png')


class MedicalEnv(gym.Env):
    def __init__(self, data):
        super(MedicalEnv, self).__init__()
        self.data = data
        self.current_index = 0
        self.action_space = gym.spaces.Discrete(2)  # Hayatta kalma (1) veya ölme (0)
        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(4,), dtype=np.float32)

    def reset(self):
        self.current_index = 0
        return self.data[self.current_index]

    def step(self, action):
        done = self.current_index >= len(self.data) - 1
        reward = self.data[self.current_index][-1] if action == 1 else 1 - self.data[self.current_index][-1]
        self.current_index += 1
        return self.data[self.current_index - 1], reward, done, {}

    def render(self, mode='human'):
        pass


file_path = 'clinical_data.xlsx'
df = pd.read_excel(file_path)


diagnoses_df = pd.json_normalize(df['diagnoses'].apply(eval).explode())
exposures_df = pd.json_normalize(df['exposures'].apply(eval).explode())

# Diagnoses DataFrame'ini orijinal DataFrame ile birleştirme
df = df.drop(columns=['diagnoses', 'exposures'])  # Eski sütunları kaldırma
df = df.merge(diagnoses_df, left_index=True, right_index=True, suffixes=('', '_diagnosis'))
df = df.merge(exposures_df, left_index=True, right_index=True, suffixes=('', '_exposure'))


selected_columns = [
    'case_id', 'demographic.gender', 'demographic.age_at_index',
    'ajcc_pathologic_t', 'cigarettes_per_day', 'pack_years_smoked',
    'demographic.vital_status'
]

final_df = df[selected_columns].copy()

final_df['gender'] = final_df['demographic.gender'].map({'male': 1, 'female': 0})
final_df['vital_status'] = final_df['demographic.vital_status'].map({'Alive': 1, 'Dead': 0})


final_df['cigarettes_per_day'].fillna(final_df['cigarettes_per_day'].mean(), inplace=True)
final_df['pack_years_smoked'].fillna(final_df['pack_years_smoked'].mean(), inplace=True)
final_df['demographic.age_at_index'].fillna(final_df['demographic.age_at_index'].mean(), inplace=True)


scaler = StandardScaler()
scaled_data = scaler.fit_transform(final_df[['demographic.age_at_index', 'cigarettes_per_day', 'pack_years_smoked', 'gender']])


env = MedicalEnv(scaled_data)


compare_models(env, nb_steps=15000)

pip install openpyxl

def sensitivity_analysis(env, nb_steps=15000):
    policies = [
        EpsGreedyQPolicy(),
        BoltzmannQPolicy(),
        GreedyQPolicy(),
        MaxBoltzmannQPolicy(),
        LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05, nb_steps=10000)
    ]
    policy_names = [
        'EpsGreedyQPolicy',
        'BoltzmannQPolicy',
        'GreedyQPolicy',
        'MaxBoltzmannQPolicy',
        'LinearAnnealedPolicy'
    ]

    learning_rates = [1e-5, 1e-4, 1e-3]
    batch_sizes = [32, 64, 128]

    sensitivity_results = []

    for policy, policy_name in zip(policies, policy_names):
        for lr in learning_rates:
            for batch_size in batch_sizes:
                print(f"\nTraining with policy: {policy_name}, learning_rate: {lr}, batch_size: {batch_size}")
                model = create_model(env)
                history, test_history = train_and_evaluate(model, policy, env, nb_steps)

              
                avg_reward = np.mean(history.history['episode_reward'])
                max_reward = np.max(history.history['episode_reward'])
                sensitivity_results.append({
                    'Policy': policy_name,
                    'Learning Rate': lr,
                    'Batch Size': batch_size,
                    'Average Reward': avg_reward,
                    'Max Reward': max_reward
                })

              
                print("Test Results:")
                for i, episode in enumerate(test_history.history['episode_reward']):
                    print(f"Episode {i+1}: reward: {episode}")

  
    sensitivity_df = pd.DataFrame(sensitivity_results)
    sensitivity_df.to_csv('sensitivity_analysis_results.csv', index=False)
    print(sensitivity_df)


    plt.figure(figsize=(18, 6))
    for policy_name in policy_names:
        subset = sensitivity_df[sensitivity_df['Policy'] == policy_name]
        plt.plot(subset['Learning Rate'], subset['Average Reward'], label=f'{policy_name} Avg Reward')
        plt.scatter(subset['Learning Rate'], subset['Max Reward'], label=f'{policy_name} Max Reward', marker='x')

    plt.xlabel('Learning Rate')
    plt.ylabel('Reward')
    plt.title('Sensitivity Analysis: Average and Max Reward vs Learning Rate', fontsize=18, fontweight='bold', pad=20)
    plt.legend(loc='upper left', fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.tight_layout()
    plt.savefig('sensitivity_analysis.png', dpi=300)
    plt.show()


class MedicalEnv(gym.Env):
    def __init__(self, data):
        super(MedicalEnv, self).__init__()
        self.data = data
        self.current_index = 0
        self.action_space = gym.spaces.Discrete(2)  
        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(4,), dtype=np.float32)

    def reset(self):
        self.current_index = 0
        return self.data[self.current_index]

    def step(self, action):
        done = self.current_index >= len(self.data) - 1
        reward = self.data[self.current_index][-1] if action == 1 else 1 - self.data[self.current_index][-1]
        self.current_index += 1
        return self.data[self.current_index - 1], reward, done, {}

    def render(self, mode='human'):
        pass


file_path = 'clinical_data.xlsx'
df = pd.read_excel(file_path)

diagnoses_df = pd.json_normalize(df['diagnoses'].apply(eval).explode())
exposures_df = pd.json_normalize(df['exposures'].apply(eval).explode())


df = df.drop(columns=['diagnoses', 'exposures'])  # Eski sütunları kaldırma
df = df.merge(diagnoses_df, left_index=True, right_index=True, suffixes=('', '_diagnosis'))
df = df.merge(exposures_df, left_index=True, right_index=True, suffixes=('', '_exposure'))


selected_columns = [
    'case_id', 'demographic.gender', 'demographic.age_at_index',
    'ajcc_pathologic_t', 'cigarettes_per_day', 'pack_years_smoked',
    'demographic.vital_status'
]

final_df = df[selected_columns].copy()


final_df['gender'] = final_df['demographic.gender'].map({'male': 1, 'female': 0})
final_df['vital_status'] = final_df['demographic.vital_status'].map({'Alive': 1, 'Dead': 0})

final_df['cigarettes_per_day'].fillna(final_df['cigarettes_per_day'].mean(), inplace=True)
final_df['pack_years_smoked'].fillna(final_df['pack_years_smoked'].mean(), inplace=True)
final_df['demographic.age_at_index'].fillna(final_df['demographic.age_at_index'].mean(), inplace=True)


scaler = StandardScaler()
scaled_data = scaler.fit_transform(final_df[['demographic.age_at_index', 'cigarettes_per_day', 'pack_years_smoked', 'gender']])


env = MedicalEnv(scaled_data)


compare_models(env, nb_steps=15000)

sensitivity_analysis(env, nb_steps=15000)
